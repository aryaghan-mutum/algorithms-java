package com.algorithms.functionalprogramming.sequential_and_paralllel_streams;

import java.util.stream.LongStream;

import static com.algorithms.functionalprogramming.sequential_and_paralllel_streams.MeasurePerformance.measureSumPerformance;

public class SequentialAndParallelStreams5 {
    
    /**
     * The main cause of errors generated by misuse of parallel miscellaneous is the use of algorithms that mutate some shared state.
     * Here’s another way to implement the sum of the first n natural numbers but by mutating a shared accumulator:
     */
    
    public static long n = 10000000;
    
    public static void main(String[] args) {
        
        System.out.println("SideEffect sequential sum done in: " + measureSumPerformance(SequentialAndParallelStreams5::sequentialStreamSum, n) + " msecs");
        System.out.println("SideEffect parallel sum done in: " + measureSumPerformance(SequentialAndParallelStreams5::sequentialParallelSum, n) + " msecs");
    }
    
    /**
     * What’s wrong with this code? Unfortunately, it’s irretrievably broken because it’s fundamentally sequential.
     * You have a data race on every access of total.
     * And if you try to fix that with synchronization, you’ll lose all your parallelism.
     * To understand this, let’s try to turn the Stream into a parallel one:
     *
     * The origin of the problem is that the method invoked inside the forEach block has the side effect of changing the mutable state of an object shared among multiple threads.
     * It’s mandatory to avoid these kinds of situations if you want to use parallel Streams without incurring similar bad surprises.
     */
    public static long sequentialStreamSum(long n) {
        Accumulator accumulator = new Accumulator();
        
        LongStream.rangeClosed(1, n)
                .sequential()
                .forEach(accumulator::add);
        
        return accumulator.total;
    }
    
    /**
     * This time the performance of your method isn’t important: the only relevant thing is that each execution returns a different result,
     * all very distant from the correct value of 50000005000000.
     * This is caused by the fact that multiple threads are concurrently accessing the accumulator and in particular executing total += value,
     * which, despite its appearance, isn’t an atomic operation.
     */
    public static long sequentialParallelSum(long n) {
        Accumulator accumulator = new Accumulator();
        
        LongStream.rangeClosed(1, n)
                .parallel()
                .forEach(accumulator::add);
        
        return accumulator.total;
    }
    
    public static class Accumulator {
        
        public long total = 0;
        
        public void add(long value) {
            total += value;
        }
    }
    
}
